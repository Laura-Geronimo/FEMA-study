

---
title: "Supplementary Information: Models"
author: "Laura Geronimo"
output:
  html_document:
    toc: true
    toc_depth: 6
    theme: united

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
##Libraries

library(ggplot2)
library(dplyr)
library(caret)

library(pacman)
library(stringr)

library(Hmisc)
library(tidycensus)
library(tidyverse)
library(corrplot)
library(data.table)
library(pastecs)
library(car)
library(gvlma)
library(qcc)
library(stargazer)

library(forcats)
library(boot)
library(bootstrap)
library(fixest)
library(lmtest)
library(sandwich)
library(cowplot)

library(pROC)
library(MASS)

library(SSVS)


options (scipen=999)

#importing data
DNZV1 <- read.csv('C:/Users/lgero/Box/Research/FEMA_project/Data/Edited/HMA/DNZLevel/DNZ_V1/DNZ_V1.csv')

DNZV1_shore <- subset(DNZV1, ZCTA_shore==1)
sum(DNZV1_shore$Elev)
sum(DNZV1_shore$Acqui)

```

## Full Sample Diagnostics


##M0 Stepwise regression on full model - all variables

Here I add all variables to the regression model and then apply stepwise AIC to see what variables are selected 
```{r include = FALSE}
M0_all <- glm(felev~
                TotPop_W_10k +
                PopDense_W_1k +
                fWhite +
                fBlack +
                fHisp +
                MHIadj_W_10k +
                MHVadj_W_100k +
                TotOccHU_W_10k +
                TotHU_W_10k +
                RepRate +
                mrp_ideology +
                fOwnOcc +
                fRentOcc +
                fS2ndHome +
                TaxBaseEst_1B_W +
                ZCTA_shore +
                count_fema_sfha_W_1k +
                NFIP_AllClaimsAdj_YOLZ +
                NFIP_ICCadj_YOLZ_W_1M +
                IHP_fldDamAmountAdjDNZ_W_10M +
                Hurricane +
                factor(StateNumLG) +
                factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M0_all)

#note: this takes processing time
stepwise_M0_all <- stepAIC(M0_all, direction = "both") #this selects the model with the lowest AIC
summary(stepwise_M0_all)

```

### Examining model chosen via initial stepwise

#### Examining variables for multicolinearity: Corr matrix and Vif test on non FE vars
```{r include = FALSE}
stepwise_M0_noFE <- glm(felev ~ 
                          TotPop_W_10k + 
                          PopDense_W_1k + 
                          fWhite + 
                          fBlack + 
                          fHisp + 
                          MHVadj_W_100k + 
                          TotHU_W_10k + 
                          mrp_ideology +
                          fS2ndHome + 
                          TaxBaseEst_1B_W + 
                          count_fema_sfha_W_1k + 
                          IHP_fldDamAmountAdjDNZ_W_10M, 
                        family = binomial(link = "logit"),  data = DNZV1_shore)

summary(stepwise_M0_noFE)

##testing for overdispersion
deviance(stepwise_M0_noFE)/df.residual(stepwise_M0_noFE) #

##testing for multicollinearity
stepwise_M0_noFE_Vif <- car::vif(stepwise_M0_noFE) #issue with fWhite, fBlack, fHisp, MHV, TotHU, MPR, and Taxbase
stepwise_M0_noFE_Vif

##Correlation Matrix
M0_vars <- DNZV1_shore[, c("TotPop_W_10k",
                          "PopDense_W_1k", 
                           "fWhite", 
                           "fBlack", 
                           "fHisp", 
                           "MHVadj_W_100k", 
                           "TotHU_W_10k", 
                           "mrp_ideology",
                           "fS2ndHome", 
                           "TaxBaseEst_1B_W",
                          "count_fema_sfha_W_1k",
                           "IHP_fldDamAmountAdjDNZ_W_10M")]

cor_M0_vars <- cor(M0_vars)
print(cor_M0_vars)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
stepwise_M0_noFE_Vif
corrplot(cor_M0_vars, method = "circle")
corrplot(cor_M0_vars,method="color", type="lower",
         addCoef.col = "black" , 
         number.cex= 0.50, 
         tl.cex=0.50, tl.col="black")
```

The VIF test indicates inflated VIF on   Tot pop, Race vars, MHV, TotHU, Tax base. 

Will need to drop some variables.



### SVSS test
Running SVSS test to see which variables are included
```{r include = FALSE}
outcome <- "felev"
predictors <- c("TotPop_W_10k",
                   "PopDense_W_1k",
                   "fWhite",
                   "fBlack",
                   "fHisp",
                   "MHIadj_W_10k",
                   "MHVadj_W_100k",
                   "TotOccHU_W_10k",
                   "TotHU_W_10k",
                   "RepRate",
                   "mrp_ideology",
                   "fOwnOcc",
                   "fRentOcc",
                   "fS2ndHome", 
                   "TaxBaseEst_1B_W",
                   #"ZCTA_shore", 
                   "count_fema_sfha_W_1k",
                   "NFIP_AllClaimsAdj_YOLZ", 
                   "NFIP_ICCadj_YOLZ_W_1M",
                   "IHP_fldDamAmountAdjDNZ_W_10M",
                   "Hurricane",                  
                   "fyDeclared",
                   "StateNumLG")


svss_fs_allvars <- ssvs(data=DNZV1_shore,
     y=outcome,
     x=predictors,
     continuous = FALSE,
     inprob=0.5,
     runs=1000,
     burn=500)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(svss_fs_allvars)

```


#### Logistic model comparing original Dissertation model with SVSS predictors 
```{r include = FALSE}
##Dis_M1: All + Baseline (w year FEs)
names(DNZV1_shore)
Dis_M1 <- glm(felev~
                MHVadj_W_100k +
                fWhite +
                RepRate +
                #ZCTA_shore +
                count_fema_sfha_W_1k +
                IHP_fldDamAmountAdjDNZ_W_10M +
                TotPop_W_10k +
                factor(StateNumLG) +
                factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(Dis_M1)

##testing for overdispersion
deviance(Dis_M1)/df.residual(Dis_M1) #

##testing for multicollinearity
Dis_M1_Vif <- car::vif(Dis_M1) #
Dis_M1_Vif

#exponentiating coeff for odds ratios
Dis_M1Exp <- Dis_M1
Dis_M1Exp$coefficients <- exp(Dis_M1Exp$coefficients)
Dis_M1Exp

# pseudo R-squared
Dis_R1 <- (1-(Dis_M1$deviance)/(Dis_M1$null.deviance))
Dis_R1 <- round(Dis_R1,2)
Dis_R1


##SVSS_M1: All + Baseline (w year FEs)
SVSS_M1 <- glm(felev~
                 fS2ndHome +
                 MHVadj_W_100k +
                 NFIP_ICCadj_YOLZ_W_1M +
                 count_fema_sfha_W_1k +
                 fHisp +
                 Hurricane +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(SVSS_M1)

##testing for overdispersion
deviance(SVSS_M1)/df.residual(SVSS_M1) #

##testing for multicollinearity
SVSS_M1_Vif <- car::vif(SVSS_M1) #
SVSS_M1_Vif

#exponentiating coeff for odds ratios
SVSS_M1Exp <- SVSS_M1
SVSS_M1Exp$coefficients <- exp(SVSS_M1Exp$coefficients)
SVSS_M1Exp

# pseudo R-squared
SVSS_R1 <- (1-(SVSS_M1$deviance)/(SVSS_M1$null.deviance))
SVSS_R1 <- round(SVSS_R1,2)
SVSS_R1

##Model All
V1 <- stargazer(Dis_M1, SVSS_M1,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes", "Yes"),
                                 c("Year FE", "Yes", "Yes"),
                                 c("Pseudo $R2$", Dis_R1, SVSS_R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/zs_dis_svss_fe.htm")

```



##Correlation Matrices on select vars
Note that in preparation for modeling, we examine all of the variables recommended in the SVSS test, plus variables that were significant in the Chi-Square and Anova tests, and are relevant to the literature based on domain knowledge. 

```{r include=FALSE}
zs_vars_V1 <- DNZV1_shore[,c("TotPop_W_10k",  #ANOVA, stepwise
                       "PopDense_W_1k",       #Stepwise
                       "fWhite",              #ANOVA, Stepwise
                       "fHisp",               #ANOVA, StepWise, SVSS
                       "MHVadj_W_100k",       #ANOVA, StepWise, SVSS
                       "TotOccHU_W_10k",      #ANOVA
                       "TotHU_W_10k",         #ANOVA, stepwise
                       "mrp_ideology",        #ANOVA, stepwise
                       "fOwnOcc",             #ANOVA
                       "fS2ndHome",           #ANOVA, stepwise, SVSS
                       "TaxBaseEst_1B_W",     #stepwise
                       "count_fema_sfha_W_1k",#ANOVA, stepwise, SVSS
                       "NFIP_ICCadj_YOLZ_W_1M", #ANOVA, SVSS
                       "IHP_fldDamAmountAdjDNZ_W_10M", #stepwise
                       "Hurricane"             #ANOVA, SVSS
                       )]        

# Calculate the correlation matrix
cor_shoreSample <- cor(zs_vars_V1)

# Print the correlation matrix
print(cor_shoreSample)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
corrplot(cor_shoreSample, method = "circle")
corrplot(cor_shoreSample, method = "color", type = "lower",
         addCoef.col = "black", 
         number.cex = 0.50, 
         tl.cex = 0.50, tl.col = "black")
```


Notes: 
-FWhite and MPR ideology are positively correlated (0.65)

-MPR ideology is negatively correlated with MHV: as MHV increase, republican ideology decreases (suggests lower-income is correlated with republicanism)
-MPR ideology and tax base are negatively correlated 



##Stepwise Regression 

## Model 1: All hypotheses & vars of interest
Developing a model that tests all hypotheses and variables of interest with control vars. 

##### Correlation Matrices for M1
```{r include=FALSE}
fs_vars_V1 <- DNZV1_shore[,c(#"TotPop_W_10k",  #ANOVA, stepwise
                       "PopDense_W_1k",       #Stepwise
                       "fWhite",              #ANOVA, Stepwise
                       #"fHisp",               #ANOVA, StepWise, SVSS
                       "MHVadj_W_100k",       #ANOVA, StepWise, SVSS
                       #"TotOccHU_W_10k",      #ANOVA
                       #"TotHU_W_10k",         #ANOVA, stepwise
                       "mrp_ideology",        #ANOVA, stepwise
                       #"fOwnOcc",             #ANOVA
                       "fS2ndHome",           #ANOVA, stepwise, SVSS
                       "TaxBaseEst_1B_W",     #stepwise
                       "count_fema_sfha_W_1k",#ANOVA, stepwise, SVSS
                       "NFIP_ICCadj_YOLZ_W_1M", #ANOVA, SVSS
                       #"IHP_fldDamAmountAdjDNZ_W_10M", #stepwise
                       "Hurricane")]          #ANOVA, SVSS

cor_fullSample <- cor(fs_vars_V1[,sapply(fs_vars_V1, is.numeric)])
print(cor_fullSample)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
corrplot(cor_fullSample, method = "circle")
corrplot(cor_fullSample,method="color", type="lower",
         addCoef.col = "black" , 
         number.cex= 0.75, 
         tl.cex=0.75, tl.col="black")
```



##### DNZV1_shore - Full model with variables of interest
Note that we order these so that the hypotheses being tested are at the top, followed by control variables
```{r include=FALSE}
# Full model 
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             IHP_fldDamAmountAdjDNZ_W_10M +
             PopDense_W_1k +            
            factor(StateNumLG) +
            factor(fyDeclared),  
           data = DNZV1_shore, family = binomial)

##testing for overdispersion
deviance(M1)/df.residual(M1) #

##testing for multicollinearity
M1_Vif <- car::vif(M1) #
M1_Vif #Issue with MHV and fWhite

```

The results of the VIF suggest MHV and fWhite perhps should not be included in the full model. Running stepwise model to select vars for this model.

##### M1 - stepwise for final variable selection
```{r include=FALSE}
#note: this takes processing time
stepwise_M1 <- stepAIC(M1, direction = "both") #this selects the model with the lowest AIC
summary(stepwise_M1)

```

The stepwise model selects the following:
MHVadj_W_100k 
mrp_ideology
fs2ndHome
coun_FEMA_sfha_W_1k
IHP_fldDamAmountAdjDNZ_W_10M
PopDense_W_1k 

Need to use other models to test hyptheses about race

#####  M1_SW - Stepwise model with fixed effects & select vars
```{r include=FALSE}
# Full model with all predictors
M1_SW <- glm(felev ~  
             MHVadj_W_100k +
             mrp_ideology +
             #fS2ndHome +
             count_fema_sfha_W_1k +
             IHP_fldDamAmountAdjDNZ_W_10M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)


##testing for overdispersion
deviance(M1_SW)/df.residual(M1_SW) #

##testing for multicollinearity
M1_SW_Vif <- car::vif(M1_SW) #Note - includes FE
M1_SW_Vif

#exponentiating coeff for odds ratios
M1_SW_Exp <- M1_SW
M1_SW_Exp$coefficients <- exp(M1_SW_Exp$coefficients)
M1_SW_Exp

# pseudo R-squared
R1 <- (1-(M1_SW$deviance)/(M1_SW$null.deviance))
R1 <- round(R1,2)
R1

##Model Viz
V1 <- stargazer(M1_SW,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/zs_M1_SW_fe.htm")



```

```{r echo=FALSE, results= 'asis'}
stargazer(M1,
                type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model 1B: Full sample (testing Race and MHV", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES"),
                                 c("Year FE", "YES"),
                                 c("Pseudo $R2$", R1)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Conservative Ideology",
                                     "Fraction 2nd Homes",
                                     "Shoreline ZCTA",
                                     "Hurricane",
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```


##### Model Series A.0: Single variable model with FE for all explanatory vars:
```{r include= FALSE}

##M0: FE 
names(DNZV1_shore)
M0 <- glm(felev~
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M0)

##testing for overdispersion
deviance(M0)/df.residual(M0)

##testing for multicollinearity
M0_Vif <- car::vif(M0) 
M0_Vif

#exponentiating coeff for odds ratios
M0Exp <- M0
M0Exp$coefficients <- exp(M0Exp$coefficients)
M0Exp

# pseudo R-squared
R0 <- (1-(M0$deviance)/(M0$null.deviance))
R0 <- round(R0,2)
R0


##M1: MHV
names(DNZV1_shore)
M1 <- glm(felev~
            MHVadj_W_100k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M1)

##testing for overdispersion
deviance(M1)/df.residual(M1)

##testing for multicollinearity
M1_Vif <- car::vif(M1) 
M1_Vif

#exponentiating coeff for odds ratios
M1Exp <- M1
M1Exp$coefficients <- exp(M1Exp$coefficients)
M1Exp

# pseudo R-squared
R1 <- (1-(M1$deviance)/(M1$null.deviance))
R1 <- round(R1,2)
R1

##M2: fWhite
names(DNZV1_shore)
M2 <- glm(felev~
            fWhite +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M2)

##testing for overdispersion
deviance(M2)/df.residual(M2)

##testing for multicollinearity
M2_Vif <- car::vif(M2) 
M2_Vif

#exponentiating coeff for odds ratios
M2Exp <- M2
M2Exp$coefficients <- exp(M2Exp$coefficients)
M2Exp

# pseudo R-squared
R2 <- (1-(M2$deviance)/(M2$null.deviance))
R2 <- round(R2,2)
R2

##M3: MPR Ideology
names(DNZV1_shore)
M3 <- glm(felev~
            mrp_ideology +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M3)

##testing for overdispersion
deviance(M3)/df.residual(M3)

##testing for multicollinearity
M3_Vif <- car::vif(M3) 
M3_Vif

#exponentiating coeff for odds ratios
M3Exp <- M3
M3Exp$coefficients <- exp(M3Exp$coefficients)
M3Exp

# pseudo R-squared
R3 <- (1-(M3$deviance)/(M3$null.deviance))
R3 <- round(R3,2)
R3

##M4: fS2ndHome
names(DNZV1_shore)
M4 <- glm(felev~
            fS2ndHome +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M4)

##testing for overdispersion
deviance(M4)/df.residual(M4)

##testing for multicollinearity
M4_Vif <- car::vif(M4) 
M4_Vif

#exponentiating coeff for odds ratios
M4Exp <- M4
M4Exp$coefficients <- exp(M4Exp$coefficients)
M4Exp

# pseudo R-squared
R4 <- (1-(M4$deviance)/(M4$null.deviance))
R4 <- round(R4,2)
R4

##M5: ZCTA_shore
names(DNZV1_shore)
M5 <- glm(felev~
            ZCTA_shore +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M5)

##testing for overdispersion
deviance(M5)/df.residual(M5)

##testing for multicollinearity
M5_Vif <- car::vif(M5) 
M5_Vif

#exponentiating coeff for odds ratios
M5Exp <- M5
M5Exp$coefficients <- exp(M5Exp$coefficients)
M5Exp

# pseudo R-squared
R5 <- (1-(M5$deviance)/(M5$null.deviance))
R5 <- round(R5,2)
R5

##M6: Hurricane
names(DNZV1_shore)
M6 <- glm(felev~
            Hurricane +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M6)

##testing for overdispersion
deviance(M6)/df.residual(M6)

##testing for multicollinearity
M6_Vif <- car::vif(M6) 
M6_Vif

#exponentiating coeff for odds ratios
M6Exp <- M6
M6Exp$coefficients <- exp(M6Exp$coefficients)
M6Exp

# pseudo R-squared
R6 <- (1-(M6$deviance)/(M6$null.deviance))
R6 <- round(R6,2)
R6

##M7: count_fema_sfha_W_1k
names(DNZV1_shore)
M7 <- glm(felev~
            count_fema_sfha_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M7)

##testing for overdispersion
deviance(M7)/df.residual(M7)

##testing for multicollinearity
M7_Vif <- car::vif(M7) 
M7_Vif

#exponentiating coeff for odds ratios
M7Exp <- M7
M7Exp$coefficients <- exp(M7Exp$coefficients)
M7Exp

# pseudo R-squared
R7 <- (1-(M7$deviance)/(M7$null.deviance))
R7 <- round(R7,2)
R7


##M8: NFIP_ICCadj_YOLZ_W_1M
names(DNZV1_shore)
M8 <- glm(felev~
            NFIP_ICCadj_YOLZ_W_1M +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M8)

##testing for overdispersion
deviance(M8)/df.residual(M8)

##testing for multicollinearity
M8_Vif <- car::vif(M8) 
M8_Vif

#exponentiating coeff for odds ratios
M8Exp <- M8
M8Exp$coefficients <- exp(M8Exp$coefficients)
M8Exp

# pseudo R-squared
R8 <- (1-(M8$deviance)/(M8$null.deviance))
R8 <- round(R8,2)
R8


##M9: PopDense_W_1k
names(DNZV1_shore)
M9 <- glm(felev~
            PopDense_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M9)

##testing for overdispersion
deviance(M9)/df.residual(M9)

##testing for multicollinearity
M9_Vif <- car::vif(M9) 
M9_Vif

#exponentiating coeff for odds ratios
M9Exp <- M9
M9Exp$coefficients <- exp(M9Exp$coefficients)
M9Exp

# pseudo R-squared
R9 <- (1-(M9$deviance)/(M9$null.deviance))
R9 <- round(R9,2)
R9


##M10: MHVadj_W_100k:fWhite
names(DNZV1_shore)
M10 <- glm(felev~
            MHVadj_W_100k*fWhite +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_shore,family=binomial(link = "logit"))
summary(M10)

##testing for overdispersion
deviance(M10)/df.residual(M10)

##testing for multicollinearity
M10_Vif <- car::vif(M10) 
M10_Vif

#exponentiating coeff for odds ratios
M10Exp <- M10
M10Exp$coefficients <- exp(M10Exp$coefficients)
M10Exp

# pseudo R-squared
R10 <- (1-(M10$deviance)/(M10$null.deviance))
R10 <- round(R10,2)
R10


#Model All
V1 <- stargazer(M0,M1,M2,M3,M4,M5,M6,M7,M8,M9,M10,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (Race & MHV)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0,R1,R2,R3,R4,R5,R6,R7,R8,R9,R10)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_fe_singleVarModels.htm")
```

```{r echo=FALSE, results= 'asis'}
stargazer(M0,M1,M2,M3,M4,M5,M6,M7,M8,M9,M10,
                type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (Race & MHV)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0,R1,R2,R3,R4,R5,R6,R7,R8,R9,R1)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Conservative Ideology",
                                     "Fraction 2nd Homes",
                                     "Shoreline ZCTA",
                                     "Hurricane",
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```



##### Model Series A.1 (Starting with best model from above and dropping vars)
```{r include= FALSE}
##M1: All vars included in stepwise model
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)


##testing for overdispersion
deviance(M1)/df.residual(M1) #

##testing for multicollinearity
M1_Vif <- car::vif(M1) ## 
M1_Vif

#exponentiating coeff for odds ratios
M1Exp <- M1
M1Exp$coefficients <- exp(M1Exp$coefficients)
M1Exp

# pseudo R-squared
R1 <- (1-(M1$deviance)/(M1$null.deviance))
R1 <- round(R1,2)
R1


##M2: dropping MHV
M2 <- glm(felev ~  
             #MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)


##testing for overdispersion
deviance(M2)/df.residual(M2) #

##testing for multicollinearity
M2_Vif <- car::vif(M2) ## 
M2_Vif

#exponentiating coeff for odds ratios
M2Exp <- M2
M2Exp$coefficients <- exp(M2Exp$coefficients)
M2Exp

# pseudo R-squared
R2 <- (1-(M2$deviance)/(M2$null.deviance))
R2 <- round(R2,2)
R2


##M3: dropping fWhite
M3 <- glm(felev ~  
             MHVadj_W_100k +
             #fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)

summary(M3)

##testing for overdispersion
deviance(M3)/df.residual(M3) #

##testing for multicollinearity
M3_Vif <- car::vif(M3) ## 
M3_Vif

#exponentiating coeff for odds ratios
M3Exp <- M3
M3Exp$coefficients <- exp(M3Exp$coefficients)
M3Exp

# pseudo R-squared
R3 <- (1-(M3$deviance)/(M3$null.deviance))
R3 <- round(R3,2)
R3


##M5: dropping mrp_ideology
M5 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             #mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)

summary(M5)

##testing for overdispersion
deviance(M5)/df.residual(M5) #

##testing for multicollinearity
M5_Vif <- car::vif(M5) ## 
M5_Vif

#exponentiating coeff for odds ratios
M5Exp <- M5
M5Exp$coefficients <- exp(M5Exp$coefficients)
M5Exp

# pseudo R-squared
R5 <- (1-(M5$deviance)/(M5$null.deviance))
R5 <- round(R5,2)
R5



##M6: dropping fS2ndHome
M6 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             #fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M6)

##testing for overdispersion
deviance(M6)/df.residual(M6) #

##testing for multicollinearity
M6_Vif <- car::vif(M6) ## 
M6_Vif

#exponentiating coeff for odds ratios
M6Exp <- M6
M6Exp$coefficients <- exp(M6Exp$coefficients)
M6Exp

# pseudo R-squared
R6 <- (1-(M6$deviance)/(M6$null.deviance))
R6 <- round(R6,2)
R6


##M7: dropping ZCTA_shore
M7 <-  glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             #ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M7)

##testing for overdispersion
deviance(M7)/df.residual(M7) #

##testing for multicollinearity
M7_Vif <- car::vif(M7) ## 
M7_Vif

#exponentiating coeff for odds ratios
M7Exp <- M7
M7Exp$coefficients <- exp(M7Exp$coefficients)
M7Exp

# pseudo R-squared
R7 <- (1-(M7$deviance)/(M7$null.deviance))
R7 <- round(R7,2)
R7



##M8: dropping Hurricane
M8 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             #Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             #IHP_fldDamAmountAdjDNZ_W_10M +  #excluded in stepwise above
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M8)

##testing for overdispersion
deviance(M8)/df.residual(M8) #

##testing for multicollinearity
M8_Vif <- car::vif(M8) ## 
M8_Vif

#exponentiating coeff for odds ratios
M8Exp <- M8
M8Exp$coefficients <- exp(M8Exp$coefficients)
M8Exp

# pseudo R-squared
R8 <- (1-(M8$deviance)/(M8$null.deviance))
R8 <- round(R8,2)
R8



##M9: dropping count_fema_sfha_W_1k
M9 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             #count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M9)

##testing for overdispersion
deviance(M9)/df.residual(M9) #

##testing for multicollinearity
M9_Vif <- car::vif(M9) ## 
M9_Vif

#exponentiating coeff for odds ratios
M9Exp <- M9
M9Exp$coefficients <- exp(M9Exp$coefficients)
M9Exp

# pseudo R-squared
R9 <- (1-(M9$deviance)/(M9$null.deviance))
R9 <- round(R9,2)
R9



##M10: dropping NFIP_ICCadj_YOLZ_W_1M
M10 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             #NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M10)

##testing for overdispersion
deviance(M10)/df.residual(M10) #

##testing for multicollinearity
M10_Vif <- car::vif(M10) ## 
M10_Vif

#exponentiating coeff for odds ratios
M10Exp <- M10
M10Exp$coefficients <- exp(M10Exp$coefficients)
M10Exp

# pseudo R-squared
R10 <- (1-(M10$deviance)/(M10$null.deviance))
R10 <- round(R10,2)
R10


##M11: dropping PopDense_W_1k
M11 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             #PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M11)

##testing for overdispersion
deviance(M11)/df.residual(M11) #

##testing for multicollinearity
M11_Vif <- car::vif(M11) ## 
M11_Vif

#exponentiating coeff for odds ratios
M11Exp <- M11
M11Exp$coefficients <- exp(M11Exp$coefficients)
M11Exp

# pseudo R-squared
R11 <- (1-(M11$deviance)/(M11$null.deviance))
R11 <- round(R11,2)
R11

##M4: dropping MHVadj_W_100k*fWhite
M4 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             #MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)


##testing for overdispersion
deviance(M4)/df.residual(M4) #

##testing for multicollinearity
M4_Vif <- car::vif(M4) ## 
M4_Vif

#exponentiating coeff for odds ratios
M4Exp <- M4
M4Exp$coefficients <- exp(M4Exp$coefficients)
M4Exp

# pseudo R-squared
R4 <- (1-(M4$deviance)/(M4$null.deviance))
R4 <- round(R4,2)
R4


#Model All
V1 <- stargazer(M1,M2,M3,M5,M6,M7,M8,M9,M10,M11,M4, type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE","YES", "YES", "YES", "YES","YES","YES","YES", "YES","YES","YES", "YES"),
                                 c("Year FE", "YES", "YES", "YES", "YES","YES","YES","YES", "YES","YES","YES", "YES"),
                                 c("Pseudo $R2$", R1,R2,R3,R5,R6,R7,R8,R9,R10,R11,R4)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_fe_dropVars.htm")
```

```{r echo=FALSE, results= 'asis'}
stargazer(M1,M2,M3,M5,M6,M7,M8,M9,M10,M11,M4, type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Full Sample, Dropping variables", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE",  "YES", "YES", "YES", "YES","YES","YES","YES", "YES","YES","YES", "YES"),
                                 c("Year FE",  "YES", "YES", "YES", "YES","YES","YES","YES", "YES","YES","YES", "YES"),
                                 c("Pseudo $R2$", R1,R2,R3,R5,R6,R7,R8,R9,R10,R11,R4)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Conservative Ideology",
                                     "Fraction 2nd Homes",
                                     "Shoreline ZCTA",
                                     "Hurricane",
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```
The model above confirms that the stepwise process selected the model with the lowest AIC


##### Post Tests M1
```{r include = FALSE}
##M1: All vars included in the final stepwise model
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore, family = binomial)
summary(M1)
```


##### Examining outliers and leverage points
###### Diagnostics:
```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(M1) #note that  3463, 1967, 339, 4397,1025,24 appear to be outliers

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

#following R in Action p. 305
# Set up a 2 by 2 plotting area
par(mfrow = c(2, 2))

# Plot 1: Predicted values vs. deviance residuals
plot(predict(M1, type = "response"),
     residuals(M1, type = "deviance"),
     main = "Predicted vs. Deviance Residuals",
     xlab = "Predicted Values",
     ylab = "Deviance Residuals")

# Plot 2: Hat values
plot(hatvalues(M1),
     main = "Hat Values",
     xlab = "Index",
     ylab = "Hat Values")

# Plot 3: Studentized residuals
plot(rstudent(M1),
     main = "Studentized Residuals",
     xlab = "Index",
     ylab = "Studentized Residuals")

# Plot 4: Cook's distance
plot(cooks.distance(M1),
     main = "Cook's Distance",
     xlab = "Index",
     ylab = "Cook's Distance")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Identifying outliers
#from book p.194
outlierTest(M1) #note that 4397 and 1025 are identified as outliers

```

```{r include= FALSE}
hat.plot <- function(M1) {
  p <- length(coefficients(M1))
  n <- length(fitted(M1))
  plot(hatvalues(M1), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(M1), names(hatvalues(M1)))
  
}

#hat.plot(M1) #getting issue here
```

######Identifying influential observations 
```{r echo=FALSE, message=FALSE, warning=FALSE}
#following (p.196)
cutoff <- 4/(nrow(DNZV1_shore)-length(M1$coefficients)-2)
plot(M1, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")  #

#assessing impact of influential observations on vars
library(car)
#avPlots(M1, ask=FALSE, id.method="identify") This takes time. Identifies similar DNZs

#influence plots
influencePlot(M1) #

#examining the rows that are indexed as leverage points 
seeLev <- DNZV1_shore[c(24,33,3463,1967,1025,4397,339),]


```


### M1_Unlev: Dropping leverage points and rerunning model 
```{r include= FALSE}
DNZV1_shore_unLev <- DNZV1_shore[c(-24,-33,-3463,-1967,-1025,-4397,-339),]


M1_unlev <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore_unLev, family = binomial)
summary(M1_unlev)


##testing for overdispersion
deviance(M1_unlev)/df.residual(M1_unlev)

##testing for multicollinearity
M1_unlev_Vif <- car::vif(M1_unlev) 
M1_unlev_Vif

#exponentiating coeff for odds ratios
M1_unlevExp <- M1_unlev
M1_unlevExp$coefficients <- exp(M1_unlevExp$coefficients)
M1_unlevExp

# pseudo R-squared
R1 <- (1-(M1_unlev$deviance)/(M1_unlev$null.deviance))
R1 <- round(R1,2)
R1

##Model All
V1 <- stargazer(M1_unlev,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_unlev_fe.htm")


```


```{r echo=FALSE, results= 'asis'}
stargazer(M1_unlev, 
          type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Dropping Influential Observations", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", R1)),
                covariate.labels = c(covariate.labels = c(
                                     "MHV ($100k W)",
                                     "Fraction White",
                                     "Conservative Ideology",
                                     "Fraction 2nd Homes",
                                     "Shoreline ZCTA",
                                     "Hurricane",
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE))
```

##### Post Tests M1_unLev
```{r include = FALSE}
##M1: All vars included in the final stepwise model
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             mrp_ideology +
             fS2ndHome +
             ZCTA_shore +
             Hurricane + 
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k+
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1_shore_unLev, family = binomial)
summary(M1)
```


##### Examining outliers and leverage points

###### Diagnostics
```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(M1) #

```


```{r echo=FALSE, message=FALSE, warning=FALSE}

#following R in Action p. 305
# Set up a 2 by 2 plotting area
par(mfrow = c(2, 2))

# Plot 1: Predicted values vs. deviance residuals
plot(predict(M1, type = "response"),
     residuals(M1, type = "deviance"),
     main = "Predicted vs. Deviance Residuals",
     xlab = "Predicted Values",
     ylab = "Deviance Residuals")

# Plot 2: Hat values
plot(hatvalues(M1),
     main = "Hat Values",
     xlab = "Index",
     ylab = "Hat Values")

# Plot 3: Studentized residuals
plot(rstudent(M1),
     main = "Studentized Residuals",
     xlab = "Index",
     ylab = "Studentized Residuals")

# Plot 4: Cook's distance
plot(cooks.distance(M1),
     main = "Cook's Distance",
     xlab = "Index",
     ylab = "Cook's Distance")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#Identifying outliers
#from book p.194
outlierTest(M1) #

```

```{r include= FALSE}
hat.plot <- function(M1) {
  p <- length(coefficients(M1))
  n <- length(fitted(M1))
  plot(hatvalues(M1), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(M1), names(hatvalues(M1)))
  
}

#hat.plot(M1) #getting issue here
```

######Identifying influential observations 
```{r echo=FALSE, message=FALSE, warning=FALSE}
#identifying influential observations (p.196)
cutoff <- 4/(nrow(DNZV1_shore_unLev)-length(M1$coefficients)-2)
plot(M1, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")

#assessing impact of influential observations on vars
library(car)
#avPlots(M1, ask=FALSE, id.method="identify") This takes time. Identifies similar DNZs

#influence plots
influencePlot(M1) #identifies 

#examining the rows that are indexed as leverage points 
seeLev <- DNZV1_shore[c(3,13,931,1569,1967),]

```

###### Drawing predicted probabilities 
```{r include= FALSE}
#following: https://www.bing.com/videos/riverview/relatedvideo?&q=logistic+regression+in+r&&mid=B29E2A8DFA23C6D477A5B29E2A8DFA23C6D477A5&&FORM=VRDGAR
predicted.data.M1 <- data.frame(probability.of.elev=M1$fitted.values,
                              felev=DNZV1_shore_unLev)

#sorting from low to high
predicted.data.M1 <- predicted.data.M1[
  order(predicted.data.M1$probability.of.elev, decreasing=FALSE),]

#add a new column to the data.frame that has the rank of each sample, from low probability to high probability
predicted.data.M1$rank <- 1:nrow(predicted.data.M1)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#draw data
ggplot(data=predicted.data.M1, aes(x=rank, y=probability.of.elev))+
  geom_point(aes(color=probability.of.elev), alpha=1, shape= 4, stroke =2)+
  xlab("Index")+
  ylab("Predicted probability of Elevation")
```

##### Cross validation
```{r include= FALSE}

##cross validation training and predition 
#p.391
DNZV1_shore_LM <- subset(DNZV1_shore_unLev, felev==0 | felev==1) #using this sample for simplicity

set.seed(1234)
train <- sample(nrow(DNZV1_shore_LM), 0.7*nrow(DNZV1_shore_LM))
DNZV1_shore_LM_train <- DNZV1_shore_LM[train,]
DNZV1_shore_LM_validate <- DNZV1_shore_LM[-train,]

#the tRaining sample will be used to create classification schemes using logistic regression, a decision tree, a conditional decision tree, a random forest, and a support vector machine

fit.logit <- glm(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=DNZV1_shore_LM_train,family=binomial(link = "logit")) #note here you are using training data
summary(fit.logit)


prob <- predict(fit.logit, DNZV1_shore_LM_validate, type="response")
logit.pred <- factor(prob >=0.5, levels=c(FALSE, TRUE),
                     labels=c("felev=0", "felev=1"))
logit.perf <- table(DNZV1_shore_LM_validate$felev, logit.pred,
                    dnn= c("Actual", "Predicted"))
logit.perf


#k-folds cross-validation 
#following: https://rforhr.com/kfold.html
library(caret)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Partition data and create index matrix of selected values
index <- createDataPartition(DNZV1_shore_LM$felev, p=.8, list=FALSE, times=1)

train_df <- DNZV1_shore_LM[index,]
test_df <- DNZV1_shore_LM[-index,]

# Re-label values of outcome variable for train_df
train_df$felev[train_df$felev==1] <- "Elev"
train_df$felev[train_df$felev==0] <- "Acqui"

# Re-label values of outcome variable for test_df
test_df$felev[test_df$felev==1] <- "Elev"
test_df$felev[test_df$felev==0] <- "Acqui"

# Convert outcome variable to factor for each data frame
train_df$felev <- as.factor(train_df$felev)
test_df$felev <- as.factor(test_df$felev)

class(DNZV1_shore_LM$ZCTA_shore)
train_df$ZCTA_shore <- as.factor(train_df$ZCTA_shore)
test_df$ZCTA_shore <- as.factor(test_df$ZCTA_shore)


# Specify type of training method used and the number of folds
ctrlspecs <- trainControl(method="cv", 
                          number=10, 
                          savePredictions="all",
                          classProbs=TRUE)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Specify logistic regression model to be estimated using training data
# and k-fold cross-validation process
model1 <- train(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=train_df,
          method="glm",
          family=binomial(link = "logit"),
          trControl=ctrlspecs)
  

# Print information about model
print(model1)

# Print results of final model estimated using training data
summary(model1)

# Estimate the importance of different predictors
varImp(model1)

# Predict outcome using model from training data based on testing data
predictions <- predict(model1, newdata=test_df)

# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

###### Confusion Matrix
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

Note: working with reduced dataset where I have removed 4 outliers from here on out


#####
```{r include= FALSE}
path1 <- ("C:/Users/lgero/Box/Research/FEMA_project/Data/Edited/HMA/DNZLevel/DNZ_V1/")
write.csv(DNZV1_shore_unLev, file.path(path1, "DNZV1_shore_unLev.csv"), row.names=TRUE)

```

