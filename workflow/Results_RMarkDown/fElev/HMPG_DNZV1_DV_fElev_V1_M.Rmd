

---
title: "Supplementary Information: Models"
author: "Laura Geronimo"
output:
  html_document:
    toc: true
    toc_depth: 6
    theme: united

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
##Libraries

library(ggplot2)
library(dplyr)
library(caret)

library(pacman)
library(stringr)

library(Hmisc)
library(tidycensus)
library(tidyverse)
library(corrplot)
library(data.table)
library(pastecs)
library(car)
library(gvlma)
library(qcc)
library(stargazer)

library(forcats)
library(boot)
library(bootstrap)
library(fixest)
library(lmtest)
library(sandwich)
library(cowplot)

library(pROC)
library(MASS)

library(SSVS)


options (scipen=999)

#importing data
DNZV1 <- read.csv('C:/Users/lgero/Box/Research/FEMA_project/Data/Edited/HMA/DNZLevel/DNZ_V1/DNZ_V1.csv')
names(DNZV1)
DNZV1 <- DNZV1[,c(-1)]



```

## Full Sample Diagnostics


##M0 Stepwise regression on full model - all variables

Here I add all variables to the regression model and then apply stepwise AIC to see what variables are selected 
```{r include = FALSE}
M0_all <- glm(felev~
                TotPop_W_10k +
                PopDense_W_1k +
                fWhite +
                fBlack +
                fHisp +
                MHIadj_W_10k +
                MHVadj_W_100k +
                TotOccHU_W_10k +
                TotHU_W_10k +
                RepRate +
                mrp_ideology +
                fOwnOcc +
                fRentOcc +
                fS2ndHome +
                TaxBaseEst_1B_W +
                ZCTA_shore +
                count_fema_sfha_W_1k +
                NFIP_AllClaimsAdj_YOLZ +
                NFIP_ICCadj_YOLZ_W_1M +
                IHP_fldDamAmountAdjDNZ_W_10M +
                Hurricane +
                factor(StateNumLG) +
                factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M0_all)

#note: this takes processing time
#stepwise_M0_all <- stepAIC(M0_all, direction = "both") #this selects the model with the lowest AIC
#summary(stepwise_M0_all)

```

### Examining model chosen via stepwise

#### Examining variables for multicolinearity: Corr matrix and Vif test on non FE vars
```{r include = FALSE}
stepwise_M0_noFE <- glm(felev ~ 
      TotPop_W_10k + 
      fHisp + 
      MHIadj_W_10k + 
      MHVadj_W_100k + 
      TotHU_W_10k + 
      fS2ndHome + 
      TaxBaseEst_1B_W + 
      ZCTA_shore + 
      count_fema_sfha_W_1k + 
      NFIP_ICCadj_YOLZ_W_1M + 
      IHP_fldDamAmountAdjDNZ_W_10M, family = binomial(link = "logit"), 
    data = DNZV1)

summary(stepwise_M0_noFE)

##testing for overdispersion
deviance(stepwise_M0_noFE)/df.residual(stepwise_M0_noFE) #

##testing for multicollinearity
stepwise_M0_noFE_Vif <- car::vif(stepwise_M0_noFE) #issue with TOtPop, TotHU, MHV, and Tax Base
stepwise_M0_noFE_Vif

##Correlation Matrix
M0_vars <- DNZV1[, c("TotPop_W_10k", "fHisp", "MHIadj_W_10k", "MHVadj_W_100k", "TotHU_W_10k", "fS2ndHome", "TaxBaseEst_1B_W", "ZCTA_shore", "count_fema_sfha_W_1k", "NFIP_ICCadj_YOLZ_W_1M")]

cor_M0_vars <- cor(M0_vars[,sapply(M0_vars, is.numeric)])
print(cor_M0_vars)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
stepwise_M0_noFE_Vif
corrplot(cor_M0_vars, method = "circle")
corrplot(cor(cor_M0_vars),method="color", type="lower",
         addCoef.col = "black" , 
         number.cex= 0.50, 
         tl.cex=0.50, tl.col="black")
```

The VIF test indicates inflated VIF on  TotPop, TotHU, MHV, MHI, and Tax Base. 
The correlation matrix indicates corr between:
  -TotPop: and TotHU (1), and fs2ndHome (-0.8), and Taxbase (0.83)
  -MHI: and MHV (0.91)
  -TotHU: and TotPop (1), and
  -fs2ndHome: and tot HU (-0.77), and taxBase (-0.72)


### SVSS test
Running SVSS test to see which variables are included
```{r include = FALSE}
outcome <- "felev"
predictors <- c("TotPop_W_10k",
                   "PopDense_W_1k",
                   "fWhite",
                   "fBlack",
                   "fHisp",
                   "MHIadj_W_10k",
                   "MHVadj_W_100k",
                   "TotOccHU_W_10k",
                   "TotHU_W_10k",
                   "RepRate",
                   "mrp_ideology",
                   "fOwnOcc",
                   "fRentOcc",
                   "fS2ndHome", 
                   "TaxBaseEst_1B_W",
                   "ZCTA_shore", 
                   "count_fema_sfha_W_1k",
                   "NFIP_AllClaimsAdj_YOLZ", 
                   "NFIP_ICCadj_YOLZ_W_1M",
                   "IHP_fldDamAmountAdjDNZ_W_10M",
                   "Hurricane",                  
                   "fyDeclared",
                   "StateNumLG")


svss_fs_allvars <- ssvs(data=DNZV1,
     y=outcome,
     x=predictors,
     continuous = FALSE,
     inprob=0.5,
     runs=1000,
     burn=500)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(svss_fs_allvars)

```


#### Logistic model comparing original Dissertation model with SVSS predictors 
```{r include = FALSE}
##Dis_M1: All + Baseline (w year FEs)
names(DNZV1)
Dis_M1 <- glm(felev~
                MHVadj_W_100k +
                fWhite +
                RepRate +
                ZCTA_shore +
                count_fema_sfha_W_1k +
                IHP_fldDamAmountAdjDNZ_W_10M +
                TotPop_W_10k +
                factor(StateNumLG) +
                factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(Dis_M1)

##testing for overdispersion
deviance(Dis_M1)/df.residual(Dis_M1) #0.52

##testing for multicollinearity
Dis_M1_Vif <- car::vif(Dis_M1) #
Dis_M1_Vif

#exponentiating coeff for odds ratios
Dis_M1Exp <- Dis_M1
Dis_M1Exp$coefficients <- exp(Dis_M1Exp$coefficients)
Dis_M1Exp

# pseudo R-squared
Dis_R1 <- (1-(Dis_M1$deviance)/(Dis_M1$null.deviance))
Dis_R1 <- round(Dis_R1,2)
Dis_R1


##SVSS_M1: All + Baseline (w year FEs)
names(DNZV1)
SVSS_M1 <- glm(felev~
            count_fema_sfha_W_1k +
            Hurricane +
            MHVadj_W_100k +
            ZCTA_shore +
            MHIadj_W_10k +
            fWhite +
            TaxBaseEst_1B_W +
            NFIP_ICCadj_YOLZ_W_1M +
            mrp_ideology +
            fWhite+
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(SVSS_M1)

##testing for overdispersion
deviance(SVSS_M1)/df.residual(SVSS_M1) #0.52

##testing for multicollinearity
SVSS_M1_Vif <- car::vif(SVSS_M1) #
SVSS_M1_Vif

#exponentiating coeff for odds ratios
SVSS_M1Exp <- SVSS_M1
SVSS_M1Exp$coefficients <- exp(SVSS_M1Exp$coefficients)
SVSS_M1Exp

# pseudo R-squared
SVSS_R1 <- (1-(SVSS_M1$deviance)/(SVSS_M1$null.deviance))
SVSS_R1 <- round(SVSS_R1,2)
SVSS_R1

##Model All
V1 <- stargazer(Dis_M1, SVSS_M1,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes", "Yes"),
                                 c("Year FE", "Yes", "Yes"),
                                 c("Pseudo $R2$", Dis_R1, SVSS_R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_dis_svss_fe.htm")

```



##Correlation Matrices on select vars
Note that in preparation for modeling, we examine all of the variables recommended in the SVSS test, plus variables that were significant in the Chi-Square and Anova tests, and are relevant to the literature based on domain knowledge. 

```{r include=FALSE}
fs_vars_V1 <- DNZV1[,c("MHVadj_W_100k",         #SVSS
                       "MHIadj_W_10k",          #ANOVA
                       "fWhite",                #ANOVA
                       "mrp_ideology",          #SVSS
                       "fS2ndHome",             #ANOVA
                       "TaxBaseEst_1B_W",       #SVSS
                       "Hurricane" ,            #SVSS
                       "ZCTA_shore",            #SVSS
                       "count_fema_sfha_W_1k",  #SVSS
                       "NFIP_ICCadj_YOLZ_W_1M", #SVSS
                       "PopDense_W_1k")]        #ANOVA

cor_fullSample <- cor(fs_vars_V1[,sapply(fs_vars_V1, is.numeric)])
print(cor_fullSample)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
corrplot(cor_fullSample, method = "circle")
corrplot(cor(cor_fullSample),method="color", type="lower",
         addCoef.col = "black" , 
         number.cex= 0.50, 
         tl.cex=0.50, tl.col="black")
```

Given the high correlation between MHV and MHI, we drop MHI.

Note that there is significant correlation between several variables of interest, including MPR, MHV, tax base, fWhite, and population density.

Some notes: 
-MPR ideology is negatively correlated with MHV: as MHV increase, republican ideology decreases (suggests lower-income is correlated with republicanism)
-MPR ideology is positively correlated with tax base
-Tax base and MHV are positively correlated
-FWhite and MPR ideology are positively correlated
-fWhite is negatively correlated with a lot of the exposure variables, like Hurricane, ZCTA_Shore, and count_FEMA SFHA. However, need these controls.
- Given

Going to have to select specific hypotheses to test one at a time.


##Stepwise Regression for specific hypotheses

## Model 1: Race and Income
Model 1: testing race and income
     MHV, fWhite, MHV*fWhite, 
     ZCTA_Shore
     Hurricane
     Count_FEMA
     NFIP_ICC
     Pop_Dense


##### Correlation Matrices for M1

```{r include=FALSE}
fs_vars_V1 <- DNZV1[,c("MHVadj_W_100k",         #SVSS
                       #"MHIadj_W_10k",          #ANOVA
                       "fWhite",                #ANOVA
                       #"mrp_ideology",          #SVSS
                       #"fS2ndHome",             #ANOVA
                       #"TaxBaseEst_1B_W",       #SVSS
                       "Hurricane" ,            #SVSS
                       "ZCTA_shore",            #SVSS
                       "count_fema_sfha_W_1k",  #SVSS
                       "NFIP_ICCadj_YOLZ_W_1M", #SVSS
                       "PopDense_W_1k")]        #ANOVA

cor_fullSample <- cor(fs_vars_V1[,sapply(fs_vars_V1, is.numeric)])
print(cor_fullSample)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
corrplot(cor_fullSample, method = "circle")
corrplot(cor(cor_fullSample),method="color", type="lower",
         addCoef.col = "black" , 
         number.cex= 0.75, 
         tl.cex=0.75, tl.col="black")
```

Note that there is high cor between:
 - fWhite and popdense(-0.75)
 - fWhite and hurricane (-0.65)
 - Count_FEMA and ZCTAShore (0.64)

Including all for the moment to check VIF

##### M1 - Full model without fixed effects & select vars
```{r include=FALSE}
# Full model without fixed effects (fe)
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             Hurricane + 
             ZCTA_shore +
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k, 
           data = DNZV1, family = binomial)

stepwise_M1<- stepAIC(M1, direction = "both")  
summary(stepwise_M1)

##testing for overdispersion
deviance(stepwise_M1)/df.residual(stepwise_M1) #

##testing for multicollinearity
stepwise_M1_Vif <- car::vif(stepwise_M1) #
stepwise_M1_Vif #GOOD

```

The results of the VIF suggest that all of these variables are ok to include for M1_A. Now adding fixed effects

#####  M1 - Full model with fixed effects & select vars
```{r include=FALSE}
# Full model with all predictors
M1 <- glm(felev ~  
             MHVadj_W_100k +
             fWhite+
             MHVadj_W_100k*fWhite +
             Hurricane + 
             ZCTA_shore +
             count_fema_sfha_W_1k +
             NFIP_ICCadj_YOLZ_W_1M +
             PopDense_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared), 
            data = DNZV1, family = binomial)


stepwise_M1 <- stepAIC(M1, direction = "both")
summary(stepwise_M1)  #note this model drops Hurricane

##testing for overdispersion
deviance(stepwise_M1)/df.residual(stepwise_M1) #

##testing for multicollinearity
stepwise_M1_Vif <- car::vif(stepwise_M1) #
stepwise_M1_Vif

#exponentiating coeff for odds ratios
stepwise_M1_Exp <- stepwise_M1
stepwise_M1_Exp$coefficients <- exp(stepwise_M1_Exp$coefficients)
stepwise_M1_Exp

# pseudo R-squared
stepwise_R1 <- (1-(stepwise_M1$deviance)/(stepwise_M1$null.deviance))
stepwise_R1 <- round(stepwise_R1,2)
stepwise_R1

##Model Viz
V1 <- stargazer(stepwise_M1,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", stepwise_R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_fe.htm")



```

```{r echo=FALSE, results= 'asis'}
stargazer(stepwise_M1,
                type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model 1B: Full sample (testing Race and MHV", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES"),
                                 c("Year FE", "YES"),
                                 c("Pseudo $R2$", stepwise_R1)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```


##### Model Series A.0: Single variable model with FE for all explanatory vars:
```{r include= FALSE}

##M0: FE 
names(DNZV1)
M0 <- glm(felev~
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M0)

##testing for overdispersion
deviance(M0)/df.residual(M0)

##testing for multicollinearity
M0_Vif <- car::vif(M0) 
M0_Vif

#exponentiating coeff for odds ratios
M0Exp <- M0
M0Exp$coefficients <- exp(M0Exp$coefficients)
M0Exp

# pseudo R-squared
R0 <- (1-(M0$deviance)/(M0$null.deviance))
R0 <- round(R0,2)
R0


##M1: MHV
names(DNZV1)
M1 <- glm(felev~
            MHVadj_W_100k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M1)

##testing for overdispersion
deviance(M1)/df.residual(M1)

##testing for multicollinearity
M1_Vif <- car::vif(M1) 
M1_Vif

#exponentiating coeff for odds ratios
M1Exp <- M1
M1Exp$coefficients <- exp(M1Exp$coefficients)
M1Exp

# pseudo R-squared
R1 <- (1-(M1$deviance)/(M1$null.deviance))
R1 <- round(R1,2)
R1

##M2: fWhite
names(DNZV1)
M2 <- glm(felev~
            fWhite +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M2)

##testing for overdispersion
deviance(M2)/df.residual(M2)

##testing for multicollinearity
M2_Vif <- car::vif(M2) 
M2_Vif

#exponentiating coeff for odds ratios
M2Exp <- M2
M2Exp$coefficients <- exp(M2Exp$coefficients)
M2Exp

# pseudo R-squared
R2 <- (1-(M2$deviance)/(M2$null.deviance))
R2 <- round(R2,2)
R2

##M3: ZCTA_shore
names(DNZV1)
M3 <- glm(felev~
            ZCTA_shore +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M3)

##testing for overdispersion
deviance(M3)/df.residual(M3)

##testing for multicollinearity
M3_Vif <- car::vif(M3) 
M3_Vif

#exponentiating coeff for odds ratios
M3Exp <- M3
M3Exp$coefficients <- exp(M3Exp$coefficients)
M3Exp

# pseudo R-squared
R3 <- (1-(M3$deviance)/(M3$null.deviance))
R3 <- round(R3,2)
R3

##M4: count_fema_sfha_W_1k
names(DNZV1)
M4 <- glm(felev~
            count_fema_sfha_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M4)

##testing for overdispersion
deviance(M4)/df.residual(M4)

##testing for multicollinearity
M4_Vif <- car::vif(M4) 
M4_Vif

#exponentiating coeff for odds ratios
M4Exp <- M4
M4Exp$coefficients <- exp(M4Exp$coefficients)
M4Exp

# pseudo R-squared
R4 <- (1-(M4$deviance)/(M4$null.deviance))
R4 <- round(R4,2)
R4

##M5: NFIP_ICCadj_YOLZ_W_1M	
names(DNZV1)
M5 <- glm(felev~
            NFIP_ICCadj_YOLZ_W_1M	 +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M5)

##testing for overdispersion
deviance(M5)/df.residual(M5)

##testing for multicollinearity
M5_Vif <- car::vif(M5) 
M5_Vif

#exponentiating coeff for odds ratios
M5Exp <- M5
M5Exp$coefficients <- exp(M5Exp$coefficients)
M5Exp

# pseudo R-squared
R5 <- (1-(M5$deviance)/(M5$null.deviance))
R5 <- round(R5,2)
R5

##M6: PopDense_W_1k
names(DNZV1)
M6 <- glm(felev~
            PopDense_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M6)

##testing for overdispersion
deviance(M6)/df.residual(M6)

##testing for multicollinearity
M6_Vif <- car::vif(M6) 
M6_Vif

#exponentiating coeff for odds ratios
M6Exp <- M6
M6Exp$coefficients <- exp(M6Exp$coefficients)
M6Exp

# pseudo R-squared
R6 <- (1-(M6$deviance)/(M6$null.deviance))
R6 <- round(R6,2)
R6

##M7: MHVadj_W_100k:fWhite
names(DNZV1)
M7 <- glm(felev~
            MHVadj_W_100k*fWhite +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M7)

##testing for overdispersion
deviance(M7)/df.residual(M7)

##testing for multicollinearity
M7_Vif <- car::vif(M7) 
M7_Vif

#exponentiating coeff for odds ratios
M7Exp <- M7
M7Exp$coefficients <- exp(M7Exp$coefficients)
M7Exp

# pseudo R-squared
R7 <- (1-(M7$deviance)/(M7$null.deviance))
R7 <- round(R7,2)
R7


#Model All
V1 <- stargazer(M0,M1,M2,M3,M4,M5,M6,M7,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (Race & MHV)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0, R1, R2, R3, R4, R5, R6, R7)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_fe_singleVarModels.htm")
```

```{r echo=FALSE, results= 'asis'}
stargazer(M0, M1, M2, M3, M4, M5, M6, M7,
                type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (Race & MHV)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0, R1, R2, R3, R4, R5, R6, R7)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```



##### Model Series A.1 (Starting with best model from above and dropping vars)
```{r include= FALSE}
##M1: All vars included in stepwise model
M1 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M1)

##testing for overdispersion
deviance(M1)/df.residual(M1) #

##testing for multicollinearity
M1_Vif <- car::vif(M1) ## 
M1_Vif

#exponentiating coeff for odds ratios
M1Exp <- M1
M1Exp$coefficients <- exp(M1Exp$coefficients)
M1Exp

# pseudo R-squared
R1 <- (1-(M1$deviance)/(M1$null.deviance))
R1 <- round(R1,2)
R1


##M2: dropping MHV
M2 <- glm(felev ~ 
               #MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M2)

##testing for overdispersion
deviance(M2)/df.residual(M2) #

##testing for multicollinearity
M2_Vif <- car::vif(M2) ## 
M2_Vif

#exponentiating coeff for odds ratios
M2Exp <- M2
M2Exp$coefficients <- exp(M2Exp$coefficients)
M2Exp

# pseudo R-squared
R2 <- (1-(M2$deviance)/(M2$null.deviance))
R2 <- round(R2,2)
R2


##M3: dropping fWhite
M3 <- glm(felev ~ 
               MHVadj_W_100k + 
               #fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M3)

##testing for overdispersion
deviance(M3)/df.residual(M3) #

##testing for multicollinearity
M3_Vif <- car::vif(M3) ## 
M3_Vif

#exponentiating coeff for odds ratios
M3Exp <- M3
M3Exp$coefficients <- exp(M3Exp$coefficients)
M3Exp

# pseudo R-squared
R3 <- (1-(M3$deviance)/(M3$null.deviance))
R3 <- round(R3,2)
R3


##M4: dropping MHVadj_W_100k*fWhite
M4 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               #MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M4)

##testing for overdispersion
deviance(M4)/df.residual(M4) #

##testing for multicollinearity
M4_Vif <- car::vif(M4) ## 
M4_Vif

#exponentiating coeff for odds ratios
M4Exp <- M4
M4Exp$coefficients <- exp(M4Exp$coefficients)
M4Exp

# pseudo R-squared
R4 <- (1-(M4$deviance)/(M4$null.deviance))
R4 <- round(R4,2)
R4



##M5: dropping ZCTA_shore
M5 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               #ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M5)

##testing for overdispersion
deviance(M5)/df.residual(M5) #

##testing for multicollinearity
M5_Vif <- car::vif(M5) ## 
M5_Vif

#exponentiating coeff for odds ratios
M5Exp <- M5
M5Exp$coefficients <- exp(M5Exp$coefficients)
M5Exp

# pseudo R-squared
R5 <- (1-(M5$deviance)/(M5$null.deviance))
R5 <- round(R5,2)
R5



##M6: dropping count_fema_sfha_W_1k
M6 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               #count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M6)

##testing for overdispersion
deviance(M6)/df.residual(M6) #

##testing for multicollinearity
M6_Vif <- car::vif(M6) ## 
M6_Vif

#exponentiating coeff for odds ratios
M6Exp <- M6
M6Exp$coefficients <- exp(M6Exp$coefficients)
M6Exp

# pseudo R-squared
R6 <- (1-(M6$deviance)/(M6$null.deviance))
R6 <- round(R6,2)
R6


##M7: dropping NFIP_ICCadj_YOLZ_W_1M 
M7 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               #NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M7)

##testing for overdispersion
deviance(M7)/df.residual(M7) #

##testing for multicollinearity
M7_Vif <- car::vif(M7) ## 
M7_Vif

#exponentiating coeff for odds ratios
M7Exp <- M7
M7Exp$coefficients <- exp(M7Exp$coefficients)
M7Exp

# pseudo R-squared
R7 <- (1-(M7$deviance)/(M7$null.deviance))
R7 <- round(R7,2)
R7



##M8: dropping PopDense_W_1k
M8 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               #PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M8)

##testing for overdispersion
deviance(M8)/df.residual(M8) #

##testing for multicollinearity
M8_Vif <- car::vif(M8) ## 
M8_Vif

#exponentiating coeff for odds ratios
M8Exp <- M8
M8Exp$coefficients <- exp(M8Exp$coefficients)
M8Exp

# pseudo R-squared
R8 <- (1-(M8$deviance)/(M8$null.deviance))
R8 <- round(R8,2)
R8


#Model All
V1 <- stargazer(M1,M2,M3,M4,M5,M6,M7,M8, type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE","YES", "YES", "YES", "YES","YES","YES","YES", "YES"),
                                 c("Year FE", "YES", "YES", "YES", "YES","YES","YES","YES", "YES"),
                                 c("Pseudo $R2$", R1,R2,R3,R4,R5,R6,R7,R8)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_fe_dropVars.htm")
```

```{r echo=FALSE, results= 'asis'}
stargazer(M1,M2,M3,M4,M5,M6,M7,M8, type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Full Sample, Dropping variables", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE",  "YES", "YES", "YES", "YES","YES","YES","YES", "YES"),
                                 c("Year FE",  "YES", "YES", "YES", "YES","YES","YES","YES", "YES"),
                                 c("Pseudo $R2$", R1,R2,R3,R4,R5,R6,R7,R8)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction",
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE))
```
The model above confirms that the stepwise process selected the model with the lowest AIC


##### Post Tests M1
```{r include = FALSE}
##M1: All vars included in the final stepwise model
M1 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1,family=binomial(link = "logit"))
summary(M1)
```


##### Examining outliers and leverage points
###### Diagnostics:
```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(M1) #note that $4397, 3463, 339 appear to be outliers

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

#following R in Action p. 305
#plots residuals versus fitted
par(mfrow=c(2,2))
plot(predict(M1, type="response"),
     residuals(M1, type="deviance"))
plot(hatvalues(M1))
plot(rstudent(M1))
plot(cooks.distance(M1))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Identifying outliers
#from book p.194
outlierTest(M1) #note that 4397 is identified as an outlier

```

```{r include= FALSE}
hat.plot <- function(M1) {
  p <- length(coefficients(M1))
  n <- length(fitted(M1))
  plot(hatvalues(M1), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(M1), names(hatvalues(M1)))
  
}

#hat.plot(M1) #getting issue here
```

######Identifying influential observations 
```{r echo=FALSE, message=FALSE, warning=FALSE}
#following (p.196)
cutoff <- 4/(nrow(DNZV1)-length(M1$coefficients)-2)
plot(M1, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")

#assessing impact of influential observations on vars
library(car)
#avPlots(M1, ask=FALSE, id.method="identify") This takes time. Identifies similar DNZs

#influence plots
influencePlot(M1) #identifies 24,1025, 3463, and 4397 as influencers

#examining the rows that are indexed as leverage points 
seeLev <- DNZV1[c(24,1025,3463,4397,339),]

```


##### Drawing predicted probabilities 
```{r include= FALSE}
#following: https://www.bing.com/videos/riverview/relatedvideo?&q=logistic+regression+in+r&&mid=B29E2A8DFA23C6D477A5B29E2A8DFA23C6D477A5&&FORM=VRDGAR
predicted.data.M1 <- data.frame(probability.of.elev=M1$fitted.values,
                              felev=DNZV1)

#sorting from low to high
predicted.data.M1 <- predicted.data.M1[
  order(predicted.data.M1$probability.of.elev, decreasing=FALSE),]

#add a new column to the data.frame that has the rank of each sample, from low probability to high probability
predicted.data.M1$rank <- 1:nrow(predicted.data.M1)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#draw data
ggplot(data=predicted.data.M1, aes(x=rank, y=probability.of.elev))+
  geom_point(aes(color=probability.of.elev), alpha=1, shape= 4, stroke =2)+
  xlab("Index")+
  ylab("Predicted probability of Elevation")
```

##### Cross validation
```{r include= FALSE}

##cross validation training and predition 
#p.391
DNZV1_LM <- subset(DNZV1, felev==0 | felev==1) #using this sample for simplicity

set.seed(1234)
train <- sample(nrow(DNZV1_LM), 0.7*nrow(DNZV1_LM))
DNZV1_LM_train <- DNZV1_LM[train,]
DNZV1_LM_validate <- DNZV1_LM[-train,]

#the taining sample will be used to creat classification schemes using logiitic regression, a decision tree, a conditional decision tree, a random forest, and a support vector machine

fit.logit <- glm(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=DNZV1_LM_train,family=binomial(link = "logit")) #note here you are using training data
summary(fit.logit)


prob <- predict(fit.logit, DNZV1_LM_validate, type="response")
logit.pred <- factor(prob >=0.5, levels=c(FALSE, TRUE),
                     labels=c("felev=0", "felev=1"))
logit.perf <- table(DNZV1_LM_validate$felev, logit.pred,
                    dnn= c("Actual", "Predicted"))
logit.perf


#k-folds cross-validation 
#following: https://rforhr.com/kfold.html
library(caret)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Partition data and create index matrix of selected values
index <- createDataPartition(DNZV1_LM$felev, p=.8, list=FALSE, times=1)

train_df <- DNZV1_LM[index,]
test_df <- DNZV1_LM[-index,]

# Re-label values of outcome variable for train_df
train_df$felev[train_df$felev==1] <- "Elev"
train_df$felev[train_df$felev==0] <- "Acqui"

# Re-label values of outcome variable for test_df
test_df$felev[test_df$felev==1] <- "Elev"
test_df$felev[test_df$felev==0] <- "Acqui"

# Convert outcome variable to factor for each data frame
train_df$felev <- as.factor(train_df$felev)
test_df$felev <- as.factor(test_df$felev)

class(DNZV1_LM$ZCTA_shore)
train_df$ZCTA_shore <- as.factor(train_df$ZCTA_shore)
test_df$ZCTA_shore <- as.factor(test_df$ZCTA_shore)


# Specify type of training method used and the number of folds
ctrlspecs <- trainControl(method="cv", 
                          number=10, 
                          savePredictions="all",
                          classProbs=TRUE)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Specify logistic regression model to be estimated using training data
# and k-fold cross-validation process
model1 <- train(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=train_df,
          method="glm",
          family=binomial(link = "logit"),
          trControl=ctrlspecs)
  

# Print information about model
print(model1)

# Print results of final model estimated using training data
summary(model1)

# Estimate the importance of different predictors
varImp(model1)

# Predict outcome using model from training data based on testing data
predictions <- predict(model1, newdata=test_df)

# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

###### Confusion matrix
```{r echo=FALSE, message=FALSE, warning=FALSE}
confusionMatrix(data=predictions, test_df$felev)
```

### M1_Unlev: Dropping leverage points and rerunning model 
```{r include= FALSE}
DNZV1_unLev <- DNZV1[c(-24, -1025,-3463,-4397, -339),]


M1_unlev <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))


##testing for overdispersion
deviance(M1_unlev)/df.residual(M1_unlev)

##testing for multicollinearity
M1_unlev_Vif <- car::vif(M1_unlev) 
M1_unlev_Vif

#exponentiating coeff for odds ratios
M1_unlevExp <- M1_unlev
M1_unlevExp$coefficients <- exp(M1_unlevExp$coefficients)
M1_unlevExp

# pseudo R-squared
R1 <- (1-(M1_unlev$deviance)/(M1_unlev$null.deviance))
R1 <- round(R1,2)
R1

##Model All
V1 <- stargazer(M1_unlev,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", R1)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M1_unlev_fe.htm")


```


```{r echo=FALSE, results= 'asis'}
stargazer(M1_unlev, 
          type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Dropping Influential Observations", 
                dep.var.labels = c("Odds Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", R1)),
                covariate.labels = c("MHV ($100k W)",
                                     "Fraction White",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL",
                                     "Population Density 1k (W)",
                                     "MHV:Fraction White interaction",
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE))
```

##### Post Tests M1_unLev
```{r include = FALSE}
##M1: All vars included in the final stepwise model
M1 <- glm(felev ~ 
               MHVadj_W_100k + 
               fWhite + 
               MHVadj_W_100k*fWhite +
               ZCTA_shore + 
               count_fema_sfha_W_1k + 
               NFIP_ICCadj_YOLZ_W_1M + 
               PopDense_W_1k + 
               factor(StateNumLG) + 
               factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M1)
```


##### Examining outliers and leverage points

###### Diagnostics
```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(M1) #

```


```{r echo=FALSE, message=FALSE, warning=FALSE}

#following R in Action p. 305
#plots residuals versus fitted
par(mfrow=c(2,2))
plot(predict(M1, type="response"),
     residuals(M1, type="deviance"))
plot(hatvalues(M1))
plot(rstudent(M1))
plot(cooks.distance(M1))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Identifying outliers
#from book p.194
outlierTest(M1) #

```

```{r include= FALSE}
hat.plot <- function(M1) {
  p <- length(coefficients(M1))
  n <- length(fitted(M1))
  plot(hatvalues(M1), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(M1), names(hatvalues(M1)))
  
}

#hat.plot(M1) #getting issue here
```

######Identifying influential observations 
```{r echo=FALSE, message=FALSE, warning=FALSE}
#identifying influential observations (p.196)
cutoff <- 4/(nrow(DNZV1_unLev)-length(M1$coefficients)-2)
plot(M1, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")

#assessing impact of influential observations on vars
library(car)
#avPlots(M1, ask=FALSE, id.method="identify") This takes time. Identifies similar DNZs

#influence plots
influencePlot(M1) #identifies 

#examining the rows that are indexed as leverage points 
seeLev <- DNZV1[c(3,13,931,1569,1967),]

```

###### Drawing predicted probabilities 
```{r include= FALSE}
#following: https://www.bing.com/videos/riverview/relatedvideo?&q=logistic+regression+in+r&&mid=B29E2A8DFA23C6D477A5B29E2A8DFA23C6D477A5&&FORM=VRDGAR
predicted.data.M1 <- data.frame(probability.of.elev=M1$fitted.values,
                              felev=DNZV1_unLev)

#sorting from low to high
predicted.data.M1 <- predicted.data.M1[
  order(predicted.data.M1$probability.of.elev, decreasing=FALSE),]

#add a new column to the data.frame that has the rank of each sample, from low probability to high probability
predicted.data.M1$rank <- 1:nrow(predicted.data.M1)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#draw data
ggplot(data=predicted.data.M1, aes(x=rank, y=probability.of.elev))+
  geom_point(aes(color=probability.of.elev), alpha=1, shape= 4, stroke =2)+
  xlab("Index")+
  ylab("Predicted probability of Elevation")
```

##### Cross validation
```{r include= FALSE}

##cross validation training and predition 
#p.391
DNZV1_LM <- subset(DNZV1_unLev, felev==0 | felev==1) #using this sample for simplicity

set.seed(1234)
train <- sample(nrow(DNZV1_LM), 0.7*nrow(DNZV1_LM))
DNZV1_LM_train <- DNZV1_LM[train,]
DNZV1_LM_validate <- DNZV1_LM[-train,]

#the taining sample will be used to creat classification schemes using logiitic regression, a decision tree, a conditional decision tree, a random forest, and a support vector machine

fit.logit <- glm(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=DNZV1_LM_train,family=binomial(link = "logit")) #note here you are using training data
summary(fit.logit)


prob <- predict(fit.logit, DNZV1_LM_validate, type="response")
logit.pred <- factor(prob >=0.5, levels=c(FALSE, TRUE),
                     labels=c("felev=0", "felev=1"))
logit.perf <- table(DNZV1_LM_validate$felev, logit.pred,
                    dnn= c("Actual", "Predicted"))
logit.perf


#k-folds cross-validation 
#following: https://rforhr.com/kfold.html
library(caret)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Partition data and create index matrix of selected values
index <- createDataPartition(DNZV1_LM$felev, p=.8, list=FALSE, times=1)

train_df <- DNZV1_LM[index,]
test_df <- DNZV1_LM[-index,]

# Re-label values of outcome variable for train_df
train_df$felev[train_df$felev==1] <- "Elev"
train_df$felev[train_df$felev==0] <- "Acqui"

# Re-label values of outcome variable for test_df
test_df$felev[test_df$felev==1] <- "Elev"
test_df$felev[test_df$felev==0] <- "Acqui"

# Convert outcome variable to factor for each data frame
train_df$felev <- as.factor(train_df$felev)
test_df$felev <- as.factor(test_df$felev)

class(DNZV1_LM$ZCTA_shore)
train_df$ZCTA_shore <- as.factor(train_df$ZCTA_shore)
test_df$ZCTA_shore <- as.factor(test_df$ZCTA_shore)


# Specify type of training method used and the number of folds
ctrlspecs <- trainControl(method="cv", 
                          number=10, 
                          savePredictions="all",
                          classProbs=TRUE)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Specify logistic regression model to be estimated using training data
# and k-fold cross-validation process
model1 <- train(felev~
                   MHVadj_W_100k + 
                   fWhite + 
                   MHVadj_W_100k*fWhite +
                   ZCTA_shore + 
                   count_fema_sfha_W_1k + 
                   NFIP_ICCadj_YOLZ_W_1M + 
                   PopDense_W_1k + 
                   factor(StateNumLG) + 
                   factor(fyDeclared),
          data=train_df,
          method="glm",
          family=binomial(link = "logit"),
          trControl=ctrlspecs)
  

# Print information about model
print(model1)

# Print results of final model estimated using training data
summary(model1)

# Estimate the importance of different predictors
varImp(model1)

# Predict outcome using model from training data based on testing data
predictions <- predict(model1, newdata=test_df)

# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

###### Confusion Matrix
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

Note: working with reduced dataset where I have removed 4 outliers from here on out

## Model 2: MPR Ideology (conservative ideology)

##### Correlation Matrices for M2

```{r include=FALSE}
fs_vars_V1 <- DNZV1_unLev[,c(
                       "mrp_ideology",          #SVSS
                       #"MHVadj_W_100k",        #SVSS
                       "MHIadj_W_10k",          #ANOVA
                       #"fWhite",               #ANOVA - high corr 
                       #"fS2ndHome",            #ANOVA
                       #"TaxBaseEst_1B_W",      #SVSS
                       "Hurricane" ,            #SVSS
                       "ZCTA_shore",            #SVSS
                       "count_fema_sfha_W_1k",  #SVSS
                       "NFIP_ICCadj_YOLZ_W_1M", #SVSS
                       "PopDense_W_1k",         #ANOVA
                       "TotPop_W_10k",          #SVSS
                       "TotOccHU_W_10k",        #SVSS
                       "TotHU_W_10k"           #SVSS
                       )]       

cor_fullSample <- cor(fs_vars_V1[,sapply(fs_vars_V1, is.numeric)])
print(cor_fullSample)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
corrplot(cor_fullSample, method = "circle")
corrplot(cor(cor_fullSample),method="color", type="lower",
         addCoef.col = "black", 
         number.cex= 0.50, 
         tl.cex=0.50, tl.col="black")
```

Note that there is high cor between:
 - mpr_ideology and all of the pop / housing control vars (~-0.8)
      -Dropping all 
 - Count_FEMA and ZCTAShore (0.64)


### Model 2: MPR Ideology
Model 2: testing MPR IDeology
     MPR Ideology, 
     ZCTA_Shore
     Hurricane
     Count_FEMA
     NFIP_ICC


##### M2 - Full model without fixed effects & select vars
```{r include=FALSE}
# Full model without fixed effects (fe)
fs_M2_full <- glm(felev ~     
                       mrp_ideology +
                       Hurricane + 
                       ZCTA_shore +
                       count_fema_sfha_W_1k +
                       NFIP_ICCadj_YOLZ_W_1M, 
                  data = DNZV1_unLev, family = binomial)

##testing for overdispersion
deviance(fs_M2_full)/df.residual(fs_M2_full) #

##testing for multicollinearity
stepwise_M2_Vif <- car::vif(fs_M2_full) #
stepwise_M2_Vif #GOOD

```

The results of the VIF suggest that all of these variables are ok to include for M2. Now adding fixed effects

##### M2 
```{r include=FALSE}
# Full model with all predictors
fs_M2_full <- glm(felev ~     
                       mrp_ideology +
                       Hurricane + 
                       ZCTA_shore +
                       count_fema_sfha_W_1k +
                       NFIP_ICCadj_YOLZ_W_1M +
                       #PopDense_W_1k +
                       factor(StateNumLG) +
                       factor(fyDeclared), 
                  data = DNZV1_unLev, family = binomial)

```

##### Stepwise regression using AIC
```{r include=FALSE}
stepwise_M2 <- stepAIC(fs_M2_full, direction = "both")
summary(stepwise_M2)

##testing for overdispersion
deviance(stepwise_M2)/df.residual(stepwise_M2) #

##testing for multicollinearity
stepwise_M2_Vif <- car::vif(stepwise_M2) #
stepwise_M2_Vif

#exponentiating coeff for odds ratios
stepwise_M2Exp <- stepwise_M2
stepwise_M2Exp$coefficients <- exp(stepwise_M2Exp$coefficients)
stepwise_M2Exp

# pseudo R-squared
stepwise_R2 <- (1-(stepwise_M2$deviance)/(stepwise_M2$null.deviance))
stepwise_R2 <- round(stepwise_R2,2)
stepwise_R2

##Model All
V1 <- stargazer(stepwise_M2,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison", 
                dep.var.labels = c("Ratio of felev"),
                add.lines = list(c("State FE","Yes"),
                                 c("Year FE", "Yes"),
                                 c("Pseudo $R2$", stepwise_R2)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M2_fe.htm")

```


```{r echo=FALSE, results= 'asis'}
stargazer(stepwise_M2,
                type="html",
                omit=c("fyDeclared", "StateNumLG"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Series 2: Full sample (testing Political Ideology)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES"),
                                 c("Year FE", "YES"),
                                 c("Pseudo $R2$", stepwise_R1)),
                covariate.labels = c("Conservative Ideology",
                                     "Hurricane",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL"),
                digits=2,
                column.sep.width = "10pt",
                single.row = FALSE,
                align=TRUE)
```



##### Model Series A.0: Single variable model with FE for all explanatory vars:
```{r include= FALSE}

##M0: FE 
names(DNZV1_unLev)
M0 <- glm(felev~
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M0)

##testing for overdispersion
deviance(M0)/df.residual(M0)

##testing for multicollinearity
M0_Vif <- car::vif(M0) 
M0_Vif

#exponentiating coeff for odds ratios
M0Exp <- M0
M0Exp$coefficients <- exp(M0Exp$coefficients)
M0Exp

# pseudo R-squared
R0 <- (1-(M0$deviance)/(M0$null.deviance))
R0 <- round(R0,2)
R0


##M1: mrp_ideology
names(DNZV1_unLev)
M1 <- glm(felev~
            mrp_ideology +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M1)

##testing for overdispersion
deviance(M1)/df.residual(M1)

##testing for multicollinearity
M1_Vif <- car::vif(M1) 
M1_Vif

#exponentiating coeff for odds ratios
M1Exp <- M1
M1Exp$coefficients <- exp(M1Exp$coefficients)
M1Exp

# pseudo R-squared
R1 <- (1-(M1$deviance)/(M1$null.deviance))
R1 <- round(R1,2)
R1

##M2:  Hurricane 
names(DNZV1_unLev)
M2 <- glm(felev~
            Hurricane  +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M2)

##testing for overdispersion
deviance(M2)/df.residual(M2)

##testing for multicollinearity
M2_Vif <- car::vif(M2) 
M2_Vif

#exponentiating coeff for odds ratios
M2Exp <- M2
M2Exp$coefficients <- exp(M2Exp$coefficients)
M2Exp

# pseudo R-squared
R2 <- (1-(M2$deviance)/(M2$null.deviance))
R2 <- round(R2,2)
R2

##M3: ZCTA_shore
names(DNZV1_unLev)
M3 <- glm(felev~
            ZCTA_shore +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M3)

##testing for overdispersion
deviance(M3)/df.residual(M3)

##testing for multicollinearity
M3_Vif <- car::vif(M3) 
M3_Vif

#exponentiating coeff for odds ratios
M3Exp <- M3
M3Exp$coefficients <- exp(M3Exp$coefficients)
M3Exp

# pseudo R-squared
R3 <- (1-(M3$deviance)/(M3$null.deviance))
R3 <- round(R3,2)
R3

##M4: count_fema_sfha_W_1k
names(DNZV1_unLev)
M4 <- glm(felev~
            count_fema_sfha_W_1k +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M4)

##testing for overdispersion
deviance(M4)/df.residual(M4)

##testing for multicollinearity
M4_Vif <- car::vif(M4) 
M4_Vif

#exponentiating coeff for odds ratios
M4Exp <- M4
M4Exp$coefficients <- exp(M4Exp$coefficients)
M4Exp

# pseudo R-squared
R4 <- (1-(M4$deviance)/(M4$null.deviance))
R4 <- round(R4,2)
R4

##M5: NFIP_ICCadj_YOLZ_W_1M	
names(DNZV1_unLev)
M5 <- glm(felev~
            NFIP_ICCadj_YOLZ_W_1M	 +
            factor(StateNumLG) +
            factor(fyDeclared),
          data=DNZV1_unLev,family=binomial(link = "logit"))
summary(M5)

##testing for overdispersion
deviance(M5)/df.residual(M5)

##testing for multicollinearity
M5_Vif <- car::vif(M5) 
M5_Vif

#exponentiating coeff for odds ratios
M5Exp <- M5
M5Exp$coefficients <- exp(M5Exp$coefficients)
M5Exp

# pseudo R-squared
R5 <- (1-(M5$deviance)/(M5$null.deviance))
R5 <- round(R5,2)
R5

#Model All
V1 <- stargazer(M0,M1,M3,M4,M5,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (MPR Ideology)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0, R1, R3, R4, R5)),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE,
                out="C:/Users/lgero/Box/Research/FEMA_project/Results/myHMA10/DNZ_V1/felev/fs_M2_fe_singleVarModels.htm")
```

```{r echo=FALSE, results= 'asis'}
stargazer(M0,M1,M3,M4,M5,
                type="html",
                omit=c("StateNumLG","fyDeclared"),
                apply.coef=exp,
                apply.ci=exp,
                t.auto=F,
                p.auto=F,
                title="Logit Model Comparison: Single Variable Model \n Full Sample (MPR Ideology)", 
                dep.var.labels = c("odds Ratio of felev"),
                add.lines = list(c("State FE","YES","YES","YES","YES","YES"),
                                 c("Year FE", "YES","YES","YES","YES","YES"),
                                 c("Pseudo $R2$", R0, R1, R3, R4, R5)),
                covariate.labels = c("Conservative Ideology",
                                     "Shoreline ZCTA" ,
                                     "Count of HUs in FEMA SFHA 1k (W)",
                                     "NFIP ICC Claims 1M (W) by ZCTA-YOL"),
                digits=2,
                column.sep.width = "10pt",
                #order=order,
                single.row = FALSE,
                align=TRUE)


```



##### Post Tests M2_unLev

```{r include = FALSE}
##M1: All vars included in the final stepwise model
M1 <- glm(felev ~     
            mrp_ideology +
            Hurricane + 
            ZCTA_shore +
            count_fema_sfha_W_1k +
            NFIP_ICCadj_YOLZ_W_1M +
            factor(StateNumLG) +
            factor(fyDeclared), 
          data = DNZV1_unLev, family = binomial)
summary(M1)
```

##### Examining outliers and leverage points

###### Diagnostics
```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(M1) 

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#following R in Action p. 305

 #plots residuals versus fitted
par(mfrow=c(2,2))
plot(predict(M1, type="response"),
     residuals(M1, type="deviance"))
plot(hatvalues(M1))
plot(rstudent(M1))
plot(cooks.distance(M1))


#Identifying outliers
#from book p.194
outlierTest(M1) #


hat.plot <- function(M1) {
  p <- length(coefficients(M1))
  n <- length(fitted(M1))
  plot(hatvalues(M1), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(M1), names(hatvalues(M1)))
  
}

#hat.plot(M1) #getting issue here
```


#identifying influential observations (p.196)
```{r echo=FALSE, message=FALSE, warning=FALSE}
#following (p.196)

cutoff <- 4/(nrow(DNZV1)-length(M1$coefficients)-2)
plot(M1, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")

#assessing impact of influential observations on vars
library(car)
#avPlots(M1, ask=FALSE, id.method="identify") This takes time. Identifies similar DNZs

#influence plots
influencePlot(M1) #identifies 


```

##### Drawing predicted probabilities 
```{r include= FALSE}
#following: https://www.bing.com/videos/riverview/relatedvideo?&q=logistic+regression+in+r&&mid=B29E2A8DFA23C6D477A5B29E2A8DFA23C6D477A5&&FORM=VRDGAR
predicted.data.M1 <- data.frame(probability.of.elev=M1$fitted.values,
                              felev=DNZV1_unLev)

#sorting from low to high
predicted.data.M1 <- predicted.data.M1[
  order(predicted.data.M1$probability.of.elev, decreasing=FALSE),]

#add a new column to the data.frame that has the rank of each sample, from low probability to high probability
predicted.data.M1$rank <- 1:nrow(predicted.data.M1)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#draw data
ggplot(data=predicted.data.M1, aes(x=rank, y=probability.of.elev))+
  geom_point(aes(color=probability.of.elev), alpha=1, shape= 4, stroke =2)+
  xlab("Index")+
  ylab("Predicted probability of Elevation")
```

##### Cross validation
```{r include= FALSE}

##cross validation training and predition 
#p.391
DNZV1_LM <- subset(DNZV1_unLev, felev==0 | felev==1) #using this sample for simplicity

set.seed(1234)
train <- sample(nrow(DNZV1_LM), 0.7*nrow(DNZV1_LM))
DNZV1_LM_train <- DNZV1_LM[train,]
DNZV1_LM_validate <- DNZV1_LM[-train,]

#the taining sample will be used to creat classification schemes using logiitic regression, a decision tree, a conditional decision tree, a random forest, and a support vector machine

fit.logit <- glm(felev~
            mrp_ideology +
            Hurricane + 
            ZCTA_shore +
            count_fema_sfha_W_1k +
            NFIP_ICCadj_YOLZ_W_1M +
            factor(StateNumLG) +
            factor(fyDeclared), 
          data=DNZV1_LM_train,family=binomial(link = "logit")) #note here you are using training data
summary(fit.logit)


prob <- predict(fit.logit, DNZV1_LM_validate, type="response")
logit.pred <- factor(prob >=0.5, levels=c(FALSE, TRUE),
                     labels=c("felev=0", "felev=1"))
logit.perf <- table(DNZV1_LM_validate$felev, logit.pred,
                    dnn= c("Actual", "Predicted"))
logit.perf


#k-folds cross-validation 
#following: https://rforhr.com/kfold.html
library(caret)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Partition data and create index matrix of selected values
index <- createDataPartition(DNZV1_LM$felev, p=.8, list=FALSE, times=1)

train_df <- DNZV1_LM[index,]
test_df <- DNZV1_LM[-index,]

# Re-label values of outcome variable for train_df
train_df$felev[train_df$felev==1] <- "Elev"
train_df$felev[train_df$felev==0] <- "Acqui"

# Re-label values of outcome variable for test_df
test_df$felev[test_df$felev==1] <- "Elev"
test_df$felev[test_df$felev==0] <- "Acqui"

# Convert outcome variable to factor for each data frame
train_df$felev <- as.factor(train_df$felev)
test_df$felev <- as.factor(test_df$felev)

class(DNZV1_LM$ZCTA_shore)
train_df$ZCTA_shore <- as.factor(train_df$ZCTA_shore)
test_df$ZCTA_shore <- as.factor(test_df$ZCTA_shore)


# Specify type of training method used and the number of folds
ctrlspecs <- trainControl(method="cv", 
                          number=10, 
                          savePredictions="all",
                          classProbs=TRUE)

# Set random seed for subsequent random selection and assignment operations
set.seed(1985)

# Specify logistic regression model to be estimated using training data
# and k-fold cross-validation process
model1 <- train(felev~
            mrp_ideology +
            Hurricane + 
            ZCTA_shore +
            count_fema_sfha_W_1k +
            NFIP_ICCadj_YOLZ_W_1M +
            factor(StateNumLG) +
            factor(fyDeclared), 
          data=train_df,
          method="glm",
          family=binomial(link = "logit"),
          trControl=ctrlspecs)
  

# Print information about model
print(model1)

# Print results of final model estimated using training data
summary(model1)

# Estimate the importance of different predictors
varImp(model1)

# Predict outcome using model from training data based on testing data
predictions <- predict(model1, newdata=test_df)

# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```

###### Confusion Matrix
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_df$felev)
```